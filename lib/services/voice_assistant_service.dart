import 'package:flutter/material.dart';
import 'package:speech_to_text/speech_to_text.dart' as stt;
import 'package:flutter_tts/flutter_tts.dart';
import 'package:permission_handler/permission_handler.dart';

class VoiceAssistantService {
  static final VoiceAssistantService _instance = VoiceAssistantService._internal();
  factory VoiceAssistantService() => _instance;
  VoiceAssistantService._internal();

  final stt.SpeechToText _speech = stt.SpeechToText();
  final FlutterTts _tts = FlutterTts();
  bool _isInitialized = false;
  bool _isSpeaking = false;

  /// ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø®Ø¯Ù…Ø©
  Future<bool> initialize() async {
    if (_isInitialized) return true;

    try {
      // Ø·Ù„Ø¨ Ø¥Ø°Ù† Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†
      final micStatus = await Permission.microphone.request();
      if (!micStatus.isGranted) {
        debugPrint('âš ï¸ Microphone permission denied');
        return false;
      }

      // ØªÙ‡ÙŠØ¦Ø© Speech-to-Text
      final speechAvailable = await _speech.initialize(
        onStatus: (status) => debugPrint('ğŸ¤ Speech status: $status'),
        onError: (error) => debugPrint('âŒ Speech error: $error'),
      );

      // ØªÙ‡ÙŠØ¦Ø© Text-to-Speech
      await _tts.setLanguage('en-US'); // ÙŠÙ…ÙƒÙ†Ùƒ ØªØºÙŠÙŠØ±Ù‡Ø§ Ù„Ù€ 'ar-SA' Ù„Ù„Ø¹Ø±Ø¨ÙŠ
      await _tts.setSpeechRate(0.5); // Ø³Ø±Ø¹Ø© Ø§Ù„ÙƒÙ„Ø§Ù… (0.5 = Ø¨Ø·ÙŠØ¡ ÙˆÙˆØ§Ø¶Ø­)
      await _tts.setVolume(1.0);
      await _tts.setPitch(1.0);

      _isInitialized = speechAvailable;
      debugPrint(_isInitialized 
          ? 'âœ… Voice Assistant initialized' 
          : 'âŒ Voice Assistant failed to initialize');
      
      return _isInitialized;
    } catch (e) {
      debugPrint('âŒ Error initializing Voice Assistant: $e');
      return false;
    }
  }

  /// Ø§Ù„ØªØ­Ø¯Ø« (Text-to-Speech)
  Future<void> speak(String text) async {
    if (!_isInitialized) {
      await initialize();
    }

    try {
      _isSpeaking = true;
      await _tts.speak(text);
      // Ø§Ù†ØªØ¸Ø± Ø­ØªÙ‰ ÙŠÙ†ØªÙ‡ÙŠ Ø§Ù„ÙƒÙ„Ø§Ù…
      await Future.delayed(Duration(milliseconds: text.length * 50));
      _isSpeaking = false;
    } catch (e) {
      debugPrint('âŒ Error speaking: $e');
      _isSpeaking = false;
    }
  }

  /// Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ÙƒÙ„Ø§Ù…
  Future<void> stopSpeaking() async {
    await _tts.stop();
    _isSpeaking = false;
  }

  /// Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹ (Speech-to-Text)
  Future<String?> listen({
    Duration timeout = const Duration(seconds: 10),
    Function(String)? onResult,
  }) async {
    if (!_isInitialized) {
      final initialized = await initialize();
      if (!initialized) return null;
    }

    if (!await _speech.hasPermission) {
      debugPrint('âš ï¸ No microphone permission');
      return null;
    }

    String? finalResult;

    try {
      await _speech.listen(
        onResult: (result) {
          if (result.finalResult) {
            finalResult = result.recognizedWords;
            debugPrint('ğŸ¤ Final: $finalResult');
          } else {
            onResult?.call(result.recognizedWords);
            debugPrint('ğŸ¤ Partial: ${result.recognizedWords}');
          }
        },
        listenFor: timeout,
        pauseFor: const Duration(seconds: 3),
        partialResults: true,
        cancelOnError: true,
        listenMode: stt.ListenMode.confirmation,
      );

      // Ø§Ù†ØªØ¸Ø± Ø­ØªÙ‰ ÙŠÙ†ØªÙ‡ÙŠ Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹
      await Future.delayed(timeout);
      await _speech.stop();

      return finalResult;
    } catch (e) {
      debugPrint('âŒ Error listening: $e');
      return null;
    }
  }

  /// Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ø§Ø³ØªÙ…Ø§Ø¹
  Future<void> stopListening() async {
    await _speech.stop();
  }

  /// ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù…Ø± Ø§Ù„ØµÙˆØªÙŠ
  VoiceCommand? analyzeCommand(String text) {
    final lowerText = text.toLowerCase().trim();
    
    // Ø£ÙˆØ§Ù…Ø± Ø§Ù„Ø£Ø¯ÙˆÙŠØ©
    if (_containsAny(lowerText, ['medication', 'medicine', 'med', 'pill', 'drug', 'Ø£Ø¯ÙˆÙŠØ©', 'Ø¯ÙˆØ§Ø¡'])) {
      if (_containsAny(lowerText, ['add', 'new', 'Ø£Ø¶Ù', 'Ø¬Ø¯ÙŠØ¯'])) {
        return VoiceCommand.addMedication;
      } else if (_containsAny(lowerText, ['edit', 'change', 'Ø¹Ø¯Ù„', 'ØºÙŠØ±'])) {
        return VoiceCommand.editMedication;
      } else if (_containsAny(lowerText, ['delete', 'remove', 'Ø§Ø­Ø°Ù', 'Ø§Ù…Ø³Ø­'])) {
        return VoiceCommand.deleteMedication;
      } else {
        return VoiceCommand.goToMedication;
      }
    }
    
    // Ø£ÙˆØ§Ù…Ø± Ø§Ù„Ù…ÙŠØ¯ÙŠØ§
    if (_containsAny(lowerText, ['media', 'video', 'music', 'listen', 'watch', 'Ù…ÙŠØ¯ÙŠØ§', 'ÙÙŠØ¯ÙŠÙˆ', 'Ø£Ø³Ù…Ø¹', 'Ø£Ø´ÙˆÙ'])) {
      return VoiceCommand.goToMedia;
    }
    
    // Ø£ÙˆØ§Ù…Ø± Ø§Ù„Ø·ÙˆØ§Ø±Ø¦
    if (_containsAny(lowerText, ['sos', 'emergency', 'help', 'Ø·ÙˆØ§Ø±Ø¦', 'Ù…Ø³Ø§Ø¹Ø¯Ø©'])) {
      return VoiceCommand.sos;
    }
    
    // Ø£ÙˆØ§Ù…Ø± Ø§Ù„Ø¹ÙˆØ¯Ø© Ù„Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
    if (_containsAny(lowerText, ['home', 'main', 'back', 'Ø±Ø¦ÙŠØ³ÙŠØ©', 'Ø±Ø¬ÙˆØ¹'])) {
      return VoiceCommand.goToHome;
    }

    return null;
  }

  /// Ù…Ø³Ø§Ø¹Ø¯ Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø£ÙŠ ÙƒÙ„Ù…Ø© Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©
  bool _containsAny(String text, List<String> keywords) {
    return keywords.any((keyword) => text.contains(keyword));
  }

  /// Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø±Ø³Ø§Ù„Ø© ØªØ±Ø­ÙŠØ¨
  String getGreeting() {
    final hour = DateTime.now().hour;
    if (hour < 12) {
      return "Good morning! How are you today?";
    } else if (hour < 17) {
      return "Good afternoon! How are you feeling?";
    } else {
      return "Good evening! How has your day been?";
    }
  }

  /// Ù…Ø­Ø§Ø¯Ø«Ø© ØªÙØ§Ø¹Ù„ÙŠØ©
  Future<void> startConversation({
    required BuildContext context,
    required Function(VoiceCommand) onCommand,
  }) async {
    // Ø³Ø¤Ø§Ù„ 1: Ø§Ù„ØªØ±Ø­ÙŠØ¨
    await speak(getGreeting());
    await Future.delayed(const Duration(seconds: 2));
    
    final response1 = await listen(timeout: const Duration(seconds: 8));
    if (response1 != null) {
      if (_containsAny(response1.toLowerCase(), ['good', 'fine', 'great', 'ØªÙ…Ø§Ù…', 'Ø¨Ø®ÙŠØ±'])) {
        await speak("That's wonderful to hear!");
      } else if (_containsAny(response1.toLowerCase(), ['bad', 'not good', 'tired', 'Ù…Ùˆ Ø²ÙŠÙ†', 'ØªØ¹Ø¨Ø§Ù†'])) {
        await speak("I'm sorry to hear that. Is there anything I can help you with?");
      }
    }

    await Future.delayed(const Duration(seconds: 2));

    // Ø³Ø¤Ø§Ù„ 2: Ù‡Ù„ ÙŠØ­ØªØ§Ø¬ Ù…Ø³Ø§Ø¹Ø¯Ø©
    await speak("Would you like me to help you navigate the app?");
    await Future.delayed(const Duration(seconds: 2));
    
    final response2 = await listen(timeout: const Duration(seconds: 8));
    if (response2 != null) {
      final command = analyzeCommand(response2);
      if (command != null) {
        onCommand(command);
        return;
      }
      
      if (_containsAny(response2.toLowerCase(), ['yes', 'sure', 'please', 'Ù†Ø¹Ù…', 'Ø£ÙŠÙˆÙ‡', 'Ø·ÙŠØ¨'])) {
        await speak("Great! Where would you like to go? You can say medication, media, or home.");
        await Future.delayed(const Duration(seconds: 2));
        
        final response3 = await listen(timeout: const Duration(seconds: 10));
        if (response3 != null) {
          final command = analyzeCommand(response3);
          if (command != null) {
            onCommand(command);
            return;
          }
        }
      }
    }

    await speak("Alright! Just tap the voice button if you need help anytime.");
  }

  bool get isSpeaking => _isSpeaking;
  bool get isInitialized => _isInitialized;

  /// ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯
  Future<void> dispose() async {
    await _tts.stop();
    await _speech.stop();
  }
}

/// Ø§Ù„Ø£ÙˆØ§Ù…Ø± Ø§Ù„ØµÙˆØªÙŠØ© Ø§Ù„Ù…ØªØ§Ø­Ø©
enum VoiceCommand {
  goToMedication,
  addMedication,
  editMedication,
  deleteMedication,
  goToMedia,
  goToHome,
  sos,
  goToSettings, // â† Ø¬Ø¯ÙŠØ¯
}